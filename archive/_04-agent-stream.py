"""
ğŸ¤– Agent ìŠ¤íŠ¸ë¦¬ë° ë²„ì „ (04-agent-stream.py)

ğŸ“‹ Agentì—ì„œ ìŠ¤íŠ¸ë¦¬ë°ì„ í™œìš©í•˜ëŠ” ë°©ë²•ë“¤:

1. ğŸ” Tool ì‹¤í–‰ ê³¼ì • ì‹¤ì‹œê°„ í‘œì‹œ
2. ğŸ§  Agentì˜ ì‚¬ê³  ê³¼ì • ë‹¨ê³„ë³„ ì¶œë ¥
3. ğŸ“Š ì¤‘ê°„ ê²°ê³¼ë¬¼ë“¤ ìˆœì°¨ì  í‘œì‹œ
4. âš¡ ì‚¬ìš©ìì—ê²Œ ì§„í–‰ ìƒí™© í”¼ë“œë°±

Agent ìŠ¤íŠ¸ë¦¬ë°ì˜ ì¥ì :
- ê° ë„êµ¬ ì‹¤í–‰ ê³¼ì •ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ í™•ì¸
- Agentì˜ ì˜ì‚¬ê²°ì • ê³¼ì • íˆ¬ëª…í™”
- ê¸´ ì‘ì—…ì˜ ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§
- ì˜¤ë¥˜ ë°œìƒ ì§€ì  ë¹ ë¥¸ íŒŒì•…
"""

from typing import Literal, Optional
from langchain_openai import ChatOpenAI
from langchain_ollama import ChatOllama
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain.agents import AgentExecutor, create_openai_tools_agent
from langchain_core.tools import tool
from langchain_core.messages import HumanMessage
import time

Provider = Literal["openai", "ollama"]

# ì„¸ì…˜ ë©”ëª¨ë¦¬ ì €ì¥ì†Œ
STORE = {}

TEMPERATURE = 0.3
TOP_P = 0.9


def get_session_history(session_id: str):
    if session_id not in STORE:
        STORE[session_id] = ChatMessageHistory()
    return STORE[session_id]


def make_llm(provider: Provider = "ollama", model: Optional[str] = None):
    if provider == "openai":
        return ChatOpenAI(
            model=model or "gpt-4.1-mini",
            temperature=TEMPERATURE,
            top_p=TOP_P,
            streaming=True,  # ğŸ”¥ Agentì—ì„œë„ ìŠ¤íŠ¸ë¦¬ë° í™œì„±í™”
        )
    else:
        return ChatOllama(
            model=model or "llama3.2",
            temperature=TEMPERATURE,
            top_p=TOP_P,
            streaming=True,  # ğŸ”¥ Agentì—ì„œë„ ìŠ¤íŠ¸ë¦¬ë° í™œì„±í™”
        )


# ğŸ”§ ì˜ˆì‹œ ë„êµ¬ë“¤ ì •ì˜
@tool
def calculate(expression: str) -> str:
    """ìˆ˜í•™ ê³„ì‚°ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì˜ˆ: calculate('2 + 2')"""
    try:
        result = eval(expression)
        return f"ê³„ì‚° ê²°ê³¼: {result}"
    except Exception as e:
        return f"ê³„ì‚° ì˜¤ë¥˜: {e}"


@tool
def get_weather(city: str) -> str:
    """ë„ì‹œì˜ ë‚ ì”¨ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    # ì‹¤ì œë¡œëŠ” API í˜¸ì¶œí•˜ì§€ë§Œ ì—¬ê¸°ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜
    time.sleep(1)  # ë„¤íŠ¸ì›Œí¬ ì§€ì—° ì‹œë®¬ë ˆì´ì…˜
    return f"{city}ì˜ ë‚ ì”¨: ë§‘ìŒ, 22Â°C"


@tool
def search_web(query: str) -> str:
    """ì›¹ì—ì„œ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    time.sleep(2)  # ê²€ìƒ‰ ì§€ì—° ì‹œë®¬ë ˆì´ì…˜
    return f"'{query}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼: ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤."


def stream_agent_execution(agent_executor, user_input: str):
    """
    ğŸ”¥ Agent ì‹¤í–‰ ê³¼ì •ì„ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ í‘œì‹œ

    Agentì˜ ê° ë‹¨ê³„ë³„ ì‹¤í–‰ ê³¼ì •ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤:
    1. Agentì˜ ì‚¬ê³  ê³¼ì • (Reasoning)
    2. ë„êµ¬ ì„ íƒ ë° ì‹¤í–‰
    3. ì¤‘ê°„ ê²°ê³¼ë“¤
    4. ìµœì¢… ì‘ë‹µ
    """
    print("ğŸ¤– Agentê°€ ì‘ì—…ì„ ì‹œì‘í•©ë‹ˆë‹¤...\n")

    # ğŸ”¥ Agent ì‹¤í–‰ ê³¼ì •ì„ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì²˜ë¦¬
    for chunk in agent_executor.stream({"input": user_input}):
        # ğŸ” ê° ì²­í¬ì˜ íƒ€ì…ê³¼ ë‚´ìš© ë¶„ì„
        if "agent" in chunk:
            # ğŸ§  Agentì˜ ì‚¬ê³  ê³¼ì •
            agent_output = chunk["agent"]
            if hasattr(agent_output, "messages") and agent_output.messages:
                for message in agent_output.messages:
                    if hasattr(message, "content"):
                        print(f"ğŸ’­ Agent ì‚¬ê³ : {message.content}")
                        print("-" * 50)

        elif "tools" in chunk:
            # ğŸ”§ ë„êµ¬ ì‹¤í–‰ ê³¼ì •
            tool_output = chunk["tools"]
            if hasattr(tool_output, "messages") and tool_output.messages:
                for message in tool_output.messages:
                    if hasattr(message, "content"):
                        print(f"ğŸ”§ ë„êµ¬ ì‹¤í–‰: {message.content}")
                        print("-" * 50)

        elif "output" in chunk:
            # ğŸ“¤ ìµœì¢… ì¶œë ¥
            print(f"âœ… ìµœì¢… ê²°ê³¼: {chunk['output']}")
            print("=" * 50)


def create_agent_with_tools(llm):
    """ë„êµ¬ê°€ í¬í•¨ëœ Agent ìƒì„±"""
    tools = [calculate, get_weather, search_web]

    prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                """ë‹¹ì‹ ì€ ë„êµ¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
        
ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë“¤:
- calculate: ìˆ˜í•™ ê³„ì‚°
- get_weather: ë‚ ì”¨ ì •ë³´ ì¡°íšŒ
- search_web: ì›¹ ê²€ìƒ‰

ê° ë‹¨ê³„ë³„ë¡œ ë¬´ì—‡ì„ í•˜ê³  ìˆëŠ”ì§€ ëª…í™•íˆ ì„¤ëª…í•˜ê³ , 
ë„êµ¬ë¥¼ ì‚¬ìš©í•  ë•ŒëŠ” ì™œ ê·¸ ë„êµ¬ë¥¼ ì„ íƒí–ˆëŠ”ì§€ ì´ìœ ë¥¼ ì„¤ëª…í•˜ì„¸ìš”.
í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ì„¸ìš”.""",
            ),
            ("human", "{input}"),
            MessagesPlaceholder(variable_name="agent_scratchpad"),
        ]
    )

    agent = create_openai_tools_agent(llm, tools, prompt)
    return AgentExecutor(agent=agent, tools=tools, verbose=True)


def main():
    """Agent ìŠ¤íŠ¸ë¦¬ë° ë°ëª¨"""
    print("ğŸ¤– Agent ìŠ¤íŠ¸ë¦¬ë° ë°ëª¨")
    print("=" * 50)

    provider = input("Provider ì„ íƒ (openai / ollama) [ollama]: ").strip() or "ollama"
    model = input("ëª¨ë¸ ì´ë¦„ (ë¹„ì›Œë‘ë©´ ê¸°ë³¸ê°’): ").strip() or None

    llm = make_llm(provider=provider, model=model)
    agent_executor = create_agent_with_tools(llm)

    print("\nì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë“¤:")
    print("- calculate: ìˆ˜í•™ ê³„ì‚°")
    print("- get_weather: ë‚ ì”¨ ì •ë³´")
    print("- search_web: ì›¹ ê²€ìƒ‰")
    print("\nëŒ€í™”ë¥¼ ì‹œì‘í•˜ì„¸ìš”! (ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ë˜ëŠ” 'quit')")

    while True:
        user_input = input("\nğŸ‘¤ You: ")

        if user_input.lower() in {"exit", "quit"}:
            print("ğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        # ğŸ”¥ Agent ì‹¤í–‰ ê³¼ì •ì„ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ í‘œì‹œ
        stream_agent_execution(agent_executor, user_input)


if __name__ == "__main__":
    main()
