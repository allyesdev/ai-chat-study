"""
ğŸš€ ê³ ê¸‰ Agent ìŠ¤íŠ¸ë¦¬ë° (05-advanced-agent-stream.py)

ğŸ“‹ ê³ ê¸‰ Agent ìŠ¤íŠ¸ë¦¬ë° ê¸°ëŠ¥ë“¤:

1. ğŸ”„ ë‹¨ê³„ë³„ ì§„í–‰ ìƒí™© í‘œì‹œ
2. â±ï¸ ê° ë‹¨ê³„ë³„ ì†Œìš” ì‹œê°„ ì¸¡ì •
3. ğŸ¯ ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ ì‹¤ì‹œê°„ í‘œì‹œ
4. ğŸ“Š ì „ì²´ ì‘ì—… ì§„í–‰ë¥  í‘œì‹œ
5. ğŸš¨ ì˜¤ë¥˜ ë°œìƒ ì‹œ ì¦‰ì‹œ ì•Œë¦¼
"""

from typing import Literal, Optional, Dict, Any
from langchain_openai import ChatOpenAI
from langchain_ollama import ChatOllama
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain.agents import AgentExecutor, create_openai_tools_agent
from langchain_core.tools import tool
from langchain_core.messages import HumanMessage
import time
import json
from datetime import datetime

Provider = Literal["openai", "ollama"]

# ì„¸ì…˜ ë©”ëª¨ë¦¬ ì €ì¥ì†Œ
STORE = {}

TEMPERATURE = 0.3
TOP_P = 0.9


def get_session_history(session_id: str):
    if session_id not in STORE:
        STORE[session_id] = ChatMessageHistory()
    return STORE[session_id]


def make_llm(provider: Provider = "ollama", model: Optional[str] = None):
    if provider == "openai":
        return ChatOpenAI(
            model=model or "gpt-4.1-mini",
            temperature=TEMPERATURE,
            top_p=TOP_P,
            streaming=True,
        )
    else:
        return ChatOllama(
            model=model or "llama3.2",
            temperature=TEMPERATURE,
            top_p=TOP_P,
            streaming=True,
        )


# ğŸ”§ ê³ ê¸‰ ë„êµ¬ë“¤ ì •ì˜
@tool
def analyze_data(data: str) -> str:
    """ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  í†µê³„ë¥¼ ì œê³µí•©ë‹ˆë‹¤."""
    time.sleep(1.5)  # ë¶„ì„ ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜
    return f"ë°ì´í„° ë¶„ì„ ì™„ë£Œ: {len(data)}ê°œ í•­ëª©, í‰ê·  ê¸¸ì´: {len(data)/10:.1f}"


@tool
def generate_report(topic: str, data: str) -> str:
    """ì£¼ì œì™€ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    time.sleep(2)  # ë³´ê³ ì„œ ìƒì„± ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜
    return f"'{topic}' ì£¼ì œì˜ ë³´ê³ ì„œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. (ë°ì´í„°: {data[:50]}...)"


@tool
def send_notification(message: str) -> str:
    """ì•Œë¦¼ì„ ì „ì†¡í•©ë‹ˆë‹¤."""
    time.sleep(0.5)
    return f"ì•Œë¦¼ ì „ì†¡ ì™„ë£Œ: {message}"


@tool
def complex_calculation(operation: str, numbers: str) -> str:
    """ë³µì¡í•œ ìˆ˜í•™ ì—°ì‚°ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
    time.sleep(1)
    try:
        # ê°„ë‹¨í•œ ì—°ì‚° ì‹œë®¬ë ˆì´ì…˜
        num_list = [float(x.strip()) for x in numbers.split(",")]
        if operation == "sum":
            result = sum(num_list)
        elif operation == "average":
            result = sum(num_list) / len(num_list)
        elif operation == "max":
            result = max(num_list)
        elif operation == "min":
            result = min(num_list)
        else:
            result = "ì§€ì›í•˜ì§€ ì•ŠëŠ” ì—°ì‚°"

        return f"{operation} ì—°ì‚° ê²°ê³¼: {result}"
    except Exception as e:
        return f"ê³„ì‚° ì˜¤ë¥˜: {e}"


class StreamingAgentMonitor:
    """ğŸ”¥ Agent ì‹¤í–‰ ê³¼ì •ì„ ëª¨ë‹ˆí„°ë§í•˜ëŠ” í´ë˜ìŠ¤"""

    def __init__(self):
        self.start_time = None
        self.step_count = 0
        self.tool_calls = []
        self.errors = []

    def start_monitoring(self):
        """ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        self.start_time = time.time()
        self.step_count = 0
        self.tool_calls = []
        self.errors = []
        print("ğŸš€ Agent ëª¨ë‹ˆí„°ë§ ì‹œì‘")
        print("=" * 60)

    def log_step(self, step_name: str, details: str = ""):
        """ë‹¨ê³„ë³„ ë¡œê¹…"""
        self.step_count += 1
        elapsed = time.time() - self.start_time if self.start_time else 0
        print(f"ğŸ“‹ ë‹¨ê³„ {self.step_count}: {step_name}")
        if details:
            print(f"   ğŸ’¡ {details}")
        print(f"   â±ï¸  ê²½ê³¼ ì‹œê°„: {elapsed:.2f}ì´ˆ")
        print("-" * 40)

    def log_tool_call(self, tool_name: str, input_data: str, result: str):
        """ë„êµ¬ í˜¸ì¶œ ë¡œê¹…"""
        self.tool_calls.append(
            {
                "tool": tool_name,
                "input": input_data,
                "result": result,
                "timestamp": datetime.now().strftime("%H:%M:%S"),
            }
        )
        print(f"ğŸ”§ ë„êµ¬ ì‹¤í–‰: {tool_name}")
        print(f"   ğŸ“¥ ì…ë ¥: {input_data[:50]}...")
        print(f"   ğŸ“¤ ê²°ê³¼: {result[:100]}...")
        print("-" * 40)

    def log_error(self, error: str):
        """ì˜¤ë¥˜ ë¡œê¹…"""
        self.errors.append(error)
        print(f"ğŸš¨ ì˜¤ë¥˜ ë°œìƒ: {error}")
        print("-" * 40)

    def finish_monitoring(self):
        """ëª¨ë‹ˆí„°ë§ ì¢…ë£Œ ë° ìš”ì•½"""
        total_time = time.time() - self.start_time if self.start_time else 0
        print("=" * 60)
        print("ğŸ“Š Agent ì‹¤í–‰ ìš”ì•½")
        print(f"   â±ï¸  ì´ ì†Œìš” ì‹œê°„: {total_time:.2f}ì´ˆ")
        print(f"   ğŸ“‹ ì´ ë‹¨ê³„ ìˆ˜: {self.step_count}")
        print(f"   ğŸ”§ ë„êµ¬ í˜¸ì¶œ ìˆ˜: {len(self.tool_calls)}")
        print(f"   ğŸš¨ ì˜¤ë¥˜ ìˆ˜: {len(self.errors)}")

        if self.tool_calls:
            print("\nğŸ”§ ì‚¬ìš©ëœ ë„êµ¬ë“¤:")
            for i, call in enumerate(self.tool_calls, 1):
                print(f"   {i}. {call['tool']} ({call['timestamp']})")

        if self.errors:
            print("\nğŸš¨ ë°œìƒí•œ ì˜¤ë¥˜ë“¤:")
            for i, error in enumerate(self.errors, 1):
                print(f"   {i}. {error}")


def stream_advanced_agent_execution(agent_executor, user_input: str):
    """ğŸ”¥ ê³ ê¸‰ Agent ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰"""
    monitor = StreamingAgentMonitor()
    monitor.start_monitoring()

    try:
        # ğŸ”¥ Agent ì‹¤í–‰ ê³¼ì •ì„ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì²˜ë¦¬
        for chunk in agent_executor.stream({"input": user_input}):
            if "agent" in chunk:
                # ğŸ§  Agentì˜ ì‚¬ê³  ê³¼ì •
                agent_output = chunk["agent"]
                if hasattr(agent_output, "messages") and agent_output.messages:
                    for message in agent_output.messages:
                        if hasattr(message, "content"):
                            monitor.log_step("Agent ì‚¬ê³  ê³¼ì •", message.content)

            elif "tools" in chunk:
                # ğŸ”§ ë„êµ¬ ì‹¤í–‰ ê³¼ì •
                tool_output = chunk["tools"]
                if hasattr(tool_output, "messages") and tool_output.messages:
                    for message in tool_output.messages:
                        if hasattr(message, "content"):
                            # ë„êµ¬ ì´ë¦„ê³¼ ì…ë ¥ ì¶”ì¶œ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ íŒŒì‹± í•„ìš”)
                            monitor.log_tool_call(
                                "ë„êµ¬", "ì…ë ¥ ë°ì´í„°", message.content
                            )

            elif "output" in chunk:
                # ğŸ“¤ ìµœì¢… ì¶œë ¥
                monitor.log_step("ìµœì¢… ê²°ê³¼ ìƒì„±", "Agentê°€ ìµœì¢… ë‹µë³€ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
                print(f"âœ… ìµœì¢… ê²°ê³¼: {chunk['output']}")

    except Exception as e:
        monitor.log_error(str(e))

    finally:
        monitor.finish_monitoring()


def create_advanced_agent_with_tools(llm):
    """ê³ ê¸‰ ë„êµ¬ê°€ í¬í•¨ëœ Agent ìƒì„±"""
    tools = [analyze_data, generate_report, send_notification, complex_calculation]

    prompt = ChatPromptTemplate.from_messages(
        [
            (
                "system",
                """ë‹¹ì‹ ì€ ê³ ê¸‰ ë„êµ¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë“¤:
- analyze_data: ë°ì´í„° ë¶„ì„ ë° í†µê³„ ì œê³µ
- generate_report: ë³´ê³ ì„œ ìƒì„±
- send_notification: ì•Œë¦¼ ì „ì†¡
- complex_calculation: ë³µì¡í•œ ìˆ˜í•™ ì—°ì‚°

ê° ë‹¨ê³„ë³„ë¡œ ì§„í–‰ ìƒí™©ì„ ëª…í™•íˆ ì„¤ëª…í•˜ê³ ,
ë„êµ¬ ì‚¬ìš© ì‹œì—ëŠ” ì…ë ¥ê³¼ ê²°ê³¼ë¥¼ ìì„¸íˆ ì„¤ëª…í•˜ì„¸ìš”.
í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ì„¸ìš”.""",
            ),
            ("human", "{input}"),
            MessagesPlaceholder(variable_name="agent_scratchpad"),
        ]
    )

    agent = create_openai_tools_agent(llm, tools, prompt)
    return AgentExecutor(agent=agent, tools=tools, verbose=True)


def main():
    """ê³ ê¸‰ Agent ìŠ¤íŠ¸ë¦¬ë° ë°ëª¨"""
    print("ğŸš€ ê³ ê¸‰ Agent ìŠ¤íŠ¸ë¦¬ë° ë°ëª¨")
    print("=" * 60)

    provider = input("Provider ì„ íƒ (openai / ollama) [ollama]: ").strip() or "ollama"
    model = input("ëª¨ë¸ ì´ë¦„ (ë¹„ì›Œë‘ë©´ ê¸°ë³¸ê°’): ").strip() or None

    llm = make_llm(provider=provider, model=model)
    agent_executor = create_advanced_agent_with_tools(llm)

    print("\nì‚¬ìš© ê°€ëŠ¥í•œ ê³ ê¸‰ ë„êµ¬ë“¤:")
    print("- analyze_data: ë°ì´í„° ë¶„ì„")
    print("- generate_report: ë³´ê³ ì„œ ìƒì„±")
    print("- send_notification: ì•Œë¦¼ ì „ì†¡")
    print("- complex_calculation: ë³µì¡í•œ ìˆ˜í•™ ì—°ì‚°")
    print("\nëŒ€í™”ë¥¼ ì‹œì‘í•˜ì„¸ìš”! (ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ë˜ëŠ” 'quit')")

    while True:
        user_input = input("\nğŸ‘¤ You: ")

        if user_input.lower() in {"exit", "quit"}:
            print("ğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        # ğŸ”¥ ê³ ê¸‰ Agent ì‹¤í–‰ ê³¼ì •ì„ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ í‘œì‹œ
        stream_advanced_agent_execution(agent_executor, user_input)


if __name__ == "__main__":
    main()
